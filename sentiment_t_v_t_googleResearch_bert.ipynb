{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_t_v_t_googleResearch_bert.ipynb","provenance":[],"collapsed_sections":["oWUSCsSkJG4o","Nh8_zPgCJbvE"],"toc_visible":true,"authorship_tag":"ABX9TyP7onB7F0Sg1uQV1QpPmI8I"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"kPOQp_LBO2OK","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJnLWfAPO5b2","colab_type":"code","colab":{}},"source":["!pip install bert-tensorflow\n","!pip install tensorflow==1.15\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzHq4ldSO3qo","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1T_tjhTO65g","colab_type":"code","colab":{}},"source":["import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NCOPZqYO_EB","colab_type":"code","colab":{}},"source":["# Set the output directory for saving model file\n","# Optionally, set a GCP bucket location\n","\n","OUTPUT_DIR = '/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg'#@param {type:\"string\"}\n","#@markdown Whether or not to clear/delete the directory and create a new one\n","DO_DELETE = False #@param {type:\"boolean\"}\n","#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n","USE_BUCKET = False #@param {type:\"boolean\"}\n","BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n","\n","if USE_BUCKET:\n","  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n","  from google.colab import auth\n","  auth.authenticate_user()\n","\n","if DO_DELETE:\n","  try:\n","    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n","  except:\n","    # Doesn't matter if the directory didn't exist\n","    pass\n","#tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YCH8_o9OICZ_","colab_type":"text"},"source":["#Dataframe\n"]},{"cell_type":"code","metadata":{"id":"4vrPFqtqPAHv","colab_type":"code","colab":{}},"source":["df_train = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/df_train_pos_neg.csv')\n","df_val = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/df_val_pos_neg.csv')\n","df_test = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/df_test_pos_neg.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiGGrhcsTgC3","colab_type":"code","colab":{}},"source":["#CHANGE VALUE OF POS: 2-->1\n","df_test['label']  = df_test['label'].replace(to_replace=2, value=1, regex=True)\n","df_val['label']   = df_val['label'].replace(to_replace=2, value=1, regex=True)\n","df_train['label'] = df_train['label'].replace(to_replace=2, value=1, regex=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSWhm6BWTiQq","colab_type":"code","colab":{}},"source":["#REMOVE LINK\n","df_train['Text'] = df_train['Text'].str.replace('http\\S+|www.\\S+', '', case=False)\n","df_val['Text']   = df_val['Text'].str.replace('http\\S+|www.\\S+', '', case=False)\n","df_test['Text']  = df_test['Text'].str.replace('http\\S+|www.\\S+', '', case=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"or8zIkG-T-op","colab_type":"code","colab":{}},"source":["X_train=df_train['Text'].values\n","y_train=df_train['label'].values\n","X_val=df_val['Text'].values\n","y_val=df_val['label'].values\n","X_test=df_test['Text'].values\n","y_test=df_test['label'].values\n","\n","#remove Emojy from tweet\n","def deEmojify(inputString):\n","    return inputString.encode('ascii', 'ignore').decode('ascii')\n","\n","for i in range(len(X_train)):\n","    X_train[i]=deEmojify(X_train[i])\n","\n","for i in range(len(X_val)):\n","    X_val[i]=deEmojify(X_val[i])\n","    \n","for i in range(len(X_test)):\n","    X_test[i]=deEmojify(X_test[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUqmVv8OUUZL","colab_type":"code","colab":{}},"source":["df_train['Text']=X_train\n","df_val['Text']=X_val\n","df_test['Text']=X_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHOJ-7QBTmRi","colab_type":"code","colab":{}},"source":["DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'label'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VRl0mfIRJU0","colab_type":"code","colab":{}},"source":["df_t = pd.DataFrame()\n","df_t[DATA_COLUMN] = df_train['Text']\n","df_t[LABEL_COLUMN] = df_train[LABEL_COLUMN]\n","df_v = pd.DataFrame()\n","df_v[DATA_COLUMN] = df_val['Text']\n","df_v[LABEL_COLUMN] = df_val[LABEL_COLUMN]\n","df_te = pd.DataFrame()\n","df_te[DATA_COLUMN] = df_test['Text']\n","df_te[LABEL_COLUMN] = df_test[LABEL_COLUMN]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp4I-TwM-oSn","colab_type":"code","colab":{}},"source":["#concat dataframe validation and dataframe test\n","frames = [df_v, df_te]\n","val_test = pd.concat(frames)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sLOpz-WFIpJq","colab_type":"text"},"source":["#Train"]},{"cell_type":"code","metadata":{"id":"Z9X8j4XUQu3H","colab_type":"code","colab":{}},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z70wNMvfVXt1","colab_type":"code","colab":{}},"source":["X_train=df_t[DATA_COLUMN].values\n","y_train=df_t[LABEL_COLUMN].values\n","#X_val=df_v[DATA_COLUMN].values\n","#y_val=df_v[LABEL_COLUMN].values\n","X_test=val_test[DATA_COLUMN].values\n","y_test=val_test[LABEL_COLUMN].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daxsfiuWVyB_","colab_type":"code","colab":{}},"source":["from tensorflow import keras\n","import os\n","import re\n","\n","train_df = pd.DataFrame(data=X_train, columns=[DATA_COLUMN])\n","train_df[LABEL_COLUMN] = y_train\n","\n","#val_df = pd.DataFrame(data=X_val, columns=[DATA_COLUMN])\n","#val_df[LABEL_COLUMN] = y_val\n","\n","test_df = pd.DataFrame(data=X_test, columns=[DATA_COLUMN])\n","test_df[LABEL_COLUMN] = y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6FTC_AOWOur","colab_type":"code","colab":{}},"source":["# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","#val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","#                                                                   text_a = x[DATA_COLUMN], \n","#                                                                   text_b = None, \n","#                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","test_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YV7qC42-WWJG","colab_type":"code","colab":{}},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","label_list = [0, 1]\n","# Convert our train and test features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","#val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUIxNPJZXb4I","colab_type":"code","colab":{}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \"\"\"Creates a classification model.\"\"\"\n","\n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]  \n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qS9cdX9QXhUl","colab_type":"code","colab":{}},"source":["# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        f1_score = tf.contrib.metrics.f1_score(\n","            label_ids,\n","            predicted_labels)\n","        auc = tf.metrics.auc(\n","            label_ids,\n","            predicted_labels)\n","        recall = tf.metrics.recall(\n","            label_ids,\n","            predicted_labels)\n","        precision = tf.metrics.precision(\n","            label_ids,\n","            predicted_labels) \n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"f1_score\": f1_score,\n","            \"auc\": auc,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","        }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SAOxwOHXjOl","colab_type":"code","colab":{}},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 5000\n","SAVE_SUMMARY_STEPS = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVX4iW-ZXk5R","colab_type":"code","colab":{}},"source":["# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jIjvRPLXmkG","colab_type":"code","colab":{}},"source":["# Specify outpit directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3XTM8HQvXnuw","colab_type":"code","colab":{}},"source":["model_fn = model_fn_builder(\n","  num_labels=2,\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gKb7LhsYgmh","colab_type":"code","colab":{}},"source":["# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_I6wy933YiJG","colab_type":"code","colab":{}},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNyLnkiPZu33","colab_type":"code","colab":{}},"source":["estimator.evaluate(input_fn=train_input_fn, steps=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kO09ysq7I149","colab_type":"text"},"source":["#Validation"]},{"cell_type":"code","metadata":{"id":"De3965_6YkWU","colab_type":"code","colab":{}},"source":["val_input_fn = run_classifier.input_fn_builder(\n","    features=val_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4FsXCgxZxgB","colab_type":"code","colab":{}},"source":["estimator.evaluate(input_fn=val_input_fn, checkpoint_path='/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZ8PfCOPI4pj","colab_type":"text"},"source":["#Test"]},{"cell_type":"code","metadata":{"id":"TTLf7spgah8o","colab_type":"code","colab":{}},"source":["test_input_fn = run_classifier.input_fn_builder(\n","    features=test_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZoH7uCJajX9","colab_type":"code","colab":{}},"source":["result = estimator.predict(input_fn=test_input_fn, checkpoint_path='/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhUjhMzbalHb","colab_type":"code","colab":{}},"source":["preds = []\n","import numpy as np \n","for prediction in result:\n","      preds.append(prediction['probabilities'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWUSCsSkJG4o","colab_type":"text"},"source":["#Results\n"]},{"cell_type":"code","metadata":{"id":"0zyLM6Twamjn","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","print(\"Accuracy of BERT is:\",accuracy_score(y_test,preds_arg))\n","print(classification_report(y_test,preds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_ythU2BbKVN","colab_type":"code","colab":{}},"source":["confusion_matrix(y_test, preds, labels=[0,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nh8_zPgCJbvE","colab_type":"text"},"source":["#Extract embeddings"]},{"cell_type":"code","metadata":{"id":"ZvKTXsmqzbus","colab_type":"code","colab":{}},"source":["! git clone https://github.com/google-research/bert.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3SvqVXezbx-","colab_type":"code","colab":{}},"source":["LAYERS = [-1,-2,-3,-4]\n","#NUM_TPU_CORES = 8\n","MAX_SEQ_LENGTH = 128\n","\n","BERT_CONFIG = '/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/bert_config.json'\n","CHKPT_DIR = '/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036'\n","VOCAB_FILE = '/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/vocab.txt'\n","INIT_CHECKPOINT = '/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036'\n","BATCH_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QMG9DYszbrM","colab_type":"code","colab":{}},"source":["import shutil, os\n","import json\n","\n","check1='/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036.data-00000-of-00001'\n","check2='/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036.index'\n","check3='/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/model.ckpt-23036.meta'\n","files = [check1,check2,check3, VOCAB_FILE, BERT_CONFIG]\n","for f in files:\n","    shutil.copy(f, '/content/tmp')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPwZZ-Mb27QJ","colab_type":"code","colab":{}},"source":["df_t\n","df_v\n","df_te\n","df_emb=pd.DataFrame()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iUi1TBApZqQ","colab_type":"code","colab":{}},"source":["data1=df_t[0:49145]\n","data2=df_t[49145:98290]\n","data3=df_t[98290:147435]\n","data4=df_t[147435:196580]\n","data5=df_t[196580:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFBkzFp93C4a","colab_type":"code","colab":{}},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6e_Wm1KQfQk","colab_type":"code","colab":{}},"source":["!pip install jsonlines\n","import jsonlines\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5P6YHsK3LR6","colab_type":"code","colab":{}},"source":["with open('/content/tmp/inputTrain.txt', 'a+') as the_file:\n","    for i in range(245724):\n","      s= data1['text'][i]\n","      s= s+\"\\n\"\n","      the_file.write(s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqmhyJzgPylc","colab_type":"code","colab":{}},"source":["with open('/content/tmp/inputVal.txt', 'a+') as the_file:\n","    for i in range(34000):\n","      s= df_v['text'][i]\n","      s= s+\"\\n\"\n","      the_file.write(s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQzyB4xEP0tG","colab_type":"code","colab":{}},"source":["with open('/content/tmp/inputTest.txt', 'a+') as the_file:\n","    for i in range(34000):\n","      s= df_te['text'][i]\n","      s= s+\"\\n\"\n","      the_file.write(s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3y4dt2O-QLEQ","colab_type":"code","colab":{}},"source":["!python /content/bert/extract_features.py \\\n","    --input_file=/content/tmp/inputTrain.txt \\\n","    --output_file=/content/tmp/output.jsonl \\\n","    --vocab_file=/content/tmp/vocab.txt \\\n","    --bert_config_file=/content/tmp/bert_config.json \\\n","    --init_checkpoint=/content/tmp/model.ckpt-23036 \\\n","    --layers=-1 \\\n","    --max_seq_length=128 \\\n","    --batch_size=32\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugdiqcfkQlnq","colab_type":"code","colab":{}},"source":["start = time.time()\n","df_emb=pd.DataFrame()\n","with jsonlines.open('/content/tmp/output.jsonl') as f:\n","    for line in f.iter():\n","        s=line['features'][0]['layers'][0]['values'] # or whatever else you'd like to do\n","        df_tmp=pd.DataFrame(s).T\n","        df_emb=df_emb.append(df_tmp,ignore_index=True)\n","end = time.time()\n","print(end - start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WVgGejY3dsef","colab":{}},"source":["import os\n","os.remove(\"/content/tmp/output.jsonl\")\n","#print(\"File Removed!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Kbagf6nRTyZ","colab_type":"code","colab":{}},"source":["!python /content/bert/extract_features.py \\\n","    --input_file=/content/tmp/inputVal.txt \\\n","    --output_file=/content/tmp/output.jsonl \\\n","    --vocab_file=/content/tmp/vocab.txt \\\n","    --bert_config_file=/content/tmp/bert_config.json \\\n","    --init_checkpoint=/content/tmp/model.ckpt-23036 \\\n","    --layers=-1 \\\n","    --max_seq_length=128 \\\n","    --batch_size=32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7J5D8OLwRUC4","colab_type":"code","colab":{}},"source":["start = time.time()\n","df_emb=pd.DataFrame()\n","with jsonlines.open('/content/tmp/output.jsonl') as f:\n","    for line in f.iter():\n","        s=line['features'][0]['layers'][0]['values'] # or whatever else you'd like to do\n","        df_tmp=pd.DataFrame(s).T\n","        df_emb=df_emb.append(df_tmp,ignore_index=True)\n","end = time.time()\n","print(end - start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cfDSqnunRUFz","colab_type":"code","colab":{}},"source":["np.savetxt(\"/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_val.csv\", df_emb, delimiter=\",\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4gllLyeSLb4","colab_type":"code","colab":{}},"source":["os.remove(\"/content/tmp/output.jsonl\")\n","print(\"File Removed!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODyVjpV6RUJF","colab_type":"code","colab":{}},"source":["!python /content/bert/extract_features.py \\\n","    --input_file=/content/tmp/inputTest.txt \\\n","    --output_file=/content/tmp/output.jsonl \\\n","    --vocab_file=/content/tmp/vocab.txt \\\n","    --bert_config_file=/content/tmp/bert_config.json \\\n","    --init_checkpoint=/content/tmp/model.ckpt-23036 \\\n","    --layers=-1 \\\n","    --max_seq_length=128 \\\n","    --batch_size=32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8V1RlnmRUMU","colab_type":"code","colab":{}},"source":["start = time.time()\n","df_emb=pd.DataFrame()\n","with jsonlines.open('/content/tmp/output.jsonl') as f:\n","    for line in f.iter():\n","        s=line['features'][0]['layers'][0]['values'] # or whatever else you'd like to do\n","        df_tmp=pd.DataFrame(s).T\n","        df_emb=df_emb.append(df_tmp,ignore_index=True)\n","end = time.time()\n","print(end - start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYxes2M4RmWq","colab_type":"code","colab":{}},"source":["np.savetxt(\"/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_test.csv\", df_emb, delimiter=\",\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywQQGRBMSMuR","colab_type":"code","colab":{}},"source":["os.remove(\"/content/tmp/output.jsonl\")\n","print(\"File Removed!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVoVd-Mv8_1j","colab_type":"code","colab":{}},"source":["train1 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train1.csv', header=None)\n","train2 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train2.csv', header=None)\n","train3 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train3.csv', header=None)\n","train4 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train4.csv', header=None)\n","train5 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train5.csv', header=None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXOtP0RK8_-Q","colab_type":"code","colab":{}},"source":["train= pd.concat([train1,train2,train3,train4,train5], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TzlrSOD8_8w","colab_type":"code","colab":{}},"source":["np.savetxt(\"/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_output_pos_neg/embedding_text_sentiment_train.csv\", train, delimiter=\",\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"thVlwkWwePdA","colab_type":"text"},"source":["#Analisi errore\n"]},{"cell_type":"code","metadata":{"id":"sCn3cvKFeJ9U","colab_type":"code","colab":{}},"source":["d1 = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/bert_prediction/predict_test_text.csv', header=None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcfyfYK3ebd2","colab_type":"code","colab":{}},"source":["d1[0]=d1[0].astype(np.int64)\n","#d1[0]\n","#d1=d1.reset_index()\n","d1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUmIkeAJeeKy","colab_type":"code","colab":{}},"source":["df_te['predicted']=d1[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRpu3iX1esf8","colab_type":"code","colab":{}},"source":["#from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","from collections import Counter\n","import itertools\n","import string\n","from nltk import wordpunct_tokenize\n","from nltk.stem.lancaster import LancasterStemmer\n","from nltk.stem import WordNetLemmatizer\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import TweetTokenizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VXTKx6zewAl","colab_type":"code","colab":{}},"source":["def text_process(dataframe):\n","  tokening = TweetTokenizer()\n","  stop =stopwords.words('english')\n","  punctuation = string.punctuation\n","  lancaster_stemmer = LancasterStemmer()\n","  word_lemmatizer = WordNetLemmatizer()\n","  stop =set(stop)\n","  #adding some of the stopwords after observing the tweets\n","  stop.add(\"The\")\n","  stop.add(\"And\")\n","  stop.add(\"I\")\n","  stop.add(\"J\")\n","  stop.add(\"K\")\n","  stop.add(\"I'd\")\n","  stop.add(\"That's\")\n","  stop.add(\"\\x81\")\n","  stop.add(\"It\")\n","  stop.add(\"I'm\")\n","  stop.add(\"...\")\n","  stop.add(\"\\x89\")\n","  stop.add(\"ĚĄ\")\n","  stop.add(\"it's\")\n","  stop.add(\"ă\")\n","  stop.add(\"\\x9d\")\n","  stop.add(\"âÂĺ\")\n","  stop.add(\"Ě\")\n","  stop.add(\"˘\")\n","  stop.add(\"Â\")\n","  stop.add(\"âÂ\")\n","  stop.add(\"Ň\")\n","  stop.add(\"http\")\n","  stop.add(\"https\")\n","  stop.add(\"co\")\n","  stop.add(\"000\")\n","  stop.add(\"Ň\")\n","  stop.add(\"Ň\")\n","  stop.add(\"Ň\")\n","  stop.add(\"de\")\n","  stop.add(\"rt\")\n","  stop.add(\"RT\")\n","  stop.add(\"..\")\n","  stop.add(\"i'm\")\n","  stop.add(\"im\")\n","\n","  stop = list(stop)\n","  dataframe = dataframe.str.lower()\n","  tweets_tokenized = dataframe.apply(tokening.tokenize)\n","  tweets_tokenized_stop = tweets_tokenized.apply(lambda x: [item for item in x if item not in stop])\n","  tweets_tokenized_stop_punct = tweets_tokenized_stop.apply(lambda x: [item for item in x if item not in punctuation])\n","  #tweets_tokenized_new_stem = tweets_tokenized_stop_punct.apply(lambda x: [lancaster_stemmer.stem(item) for item in x])\n","  tweets_tokenized_new_lem = tweets_tokenized_stop_punct.apply(lambda x: [word_lemmatizer.lemmatize(item) for item in x])\n","  sentences = (list(itertools.chain(tweets_tokenized_new_lem)))\n","  flat_list = [item for sublist in sentences for item in sublist]\n","  flat_list\n","  c = Counter(flat_list)\n","  print(c.most_common(10))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPt-WUJKex71","colab_type":"code","colab":{}},"source":["#test vari effettuati \n","\n","foto=[\"image\",\"pic\",\"pics\",\"picture\",\"images\",\"olympus\",\"canon\",\"kodak\",\"sigma\",\"nikon\", \"reflex\",\"sony\",\n","      \"fujifilm\",\"pentax\",\"panasonic\",\"iphone\",\"samsung\", \"phone\", \"iphoneography\", \"instagram\", \"square\", \n","      \"twitter\", \"tweet\",\"fb\", \"facebook\", \"follow\", \"device\",\"devices\",\"adv\",\"advertising\",\"amazon\",\"technolog\",\"innovation\",\n","      \"makro\", \"macro\", \"mm\", \"f/\",\"f1\",\"f3\",\"f2\",\"mark\",\"5d\", \"4d\",\"3d\",\"flickr\",\"filter\",\"nofilter\",\"d300\",\"35mm\",\"58mm\",\"80mm\",\n","      \"100mm\",\"2/100mm\",\"dpi\", \"app\", \"apps\", \"application\",\"polaroid\",\"portrait\",\"iphoto\"]\n","df_error=pd.DataFrame()\n","error = {0:0,1:0}\n","df_no_error=pd.DataFrame()\n","\n","for index,row in df_te.iterrows():\n","  if(row['label']!= row['predicted']):\n","    print(row['text'])\n","    if any(word in row['text'].lower() for word in foto):\n","      df_error=df_error.append(row)\n","\n","#text_process(df_error['text'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"709NnyVZnwWq","colab_type":"text"},"source":["# Fuse result"]},{"cell_type":"code","metadata":{"id":"rS1r5kB1xaMI","colab_type":"code","colab":{}},"source":["d_text = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/matrix_to_fuse.csv', header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHA4-ChWnyh3","colab_type":"code","colab":{}},"source":["pred_t=[]\n","for index,row in d_text.iterrows():\n","  pred_t.append(np.argmax(row))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJOVJ5iXwSsC","colab_type":"code","colab":{}},"source":["d_img = pd.read_csv('/content/gdrive/My Drive/Università/Tesi_magistrale/b_t4sa_imgs_old/efnet_output/predict_giugno_att', header=None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUYsvgvwoYxG","colab_type":"code","colab":{}},"source":["df_res=d_img.reset_index()\n","df_res=df_res.drop('index',axis=1)\n","df_res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t0z7wmr8JRRG","colab_type":"text"},"source":["# Max Fusion\n"]},{"cell_type":"code","metadata":{"id":"8QpTwvWioVIi","colab_type":"code","colab":{}},"source":["max_df=pd.DataFrame(columns=['text','label_t','img','label_i'])\n","#fusion max\n","label_i=[]\n","img=[]\n","for index,row in df_res.iterrows():\n","  img.append(np.max(row))\n","  label_i.append(np.argmax(row))\n","#fusion max\n","label_t=[]\n","text=[]\n","for index,row in d_text.iterrows():\n","  text.append(np.max(row))\n","  label_t.append(np.argmax(row))\n","max_df['text']=text\n","max_df['img']=img\n","max_df['label_t']=label_t\n","max_df['label_i']=label_i\n","result=[]\n","for index,row in max_df.iterrows():\n","  if(row['text']>=row['img']):\n","    result.append(int(row['label_t']))\n","  else:\n","    result.append(int(row['label_i']))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vqj-0XA5gCKE","colab_type":"code","colab":{}},"source":["print(\"Accuracy of BERT is:\",accuracy_score(y_test,result))\n","print(classification_report(y_test,result))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wJITjTUJVCY","colab_type":"text"},"source":["# Mean Fusion\n"]},{"cell_type":"code","metadata":{"id":"edijglC_5MgO","colab_type":"code","colab":{}},"source":["#fusion media\n","label_0=[]\n","label_1=[]\n","\n","for index,row in df_res.iterrows():\n","  label_0.append(row[0])\n","  label_1.append(row[1])\n","#fusion media\n","label_0_t=[]\n","label_1_t=[]\n","media_df=pd.DataFrame()\n","for index,row in d_text.iterrows():\n","  label_0_t.append(row[0])\n","  label_1_t.append(row[1])\n","from statistics import mean, median, mode, stdev\n","result_0 = [mean(k) for k in zip(label_0, label_0_t)]\n","result_1 = [mean(k) for k in zip(label_1, label_1_t)]\n","\n","media_df[0]=result_0\n","media_df[1]=result_1\n","\n","#fusion mean\n","res_mean=[]\n","for index,row in media_df.iterrows():\n","  res_mean.append(np.argmax(row))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbacX2Dog9V1","colab_type":"code","colab":{}},"source":["print(\"Accuracy of BERT is:\",accuracy_score(y_test,res_mean))\n","print(classification_report(y_test,res_mean))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e64DvqEPJeqW","colab_type":"text"},"source":["# Conf matrix "]},{"cell_type":"code","metadata":{"id":"_ilMVQh3AZFb","colab_type":"code","colab":{}},"source":["true_val=d_text['label']\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","print(\"Accuracy of BERT is:\",accuracy_score(true_val,res))\n","print(classification_report(true_val,res))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D04KbLBjGHxi","colab_type":"code","colab":{}},"source":["confusion_matrix(true_val, res, labels=[0,1])\n"],"execution_count":null,"outputs":[]}]}